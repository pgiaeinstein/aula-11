{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Atividade_1.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/generative_examples/text_generation.ipynb","timestamp":1541511228260}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"code","id":"wZ6LOM12wKGH","colab":{}},"cell_type":"code","source":["!pip install unidecode"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"yG_n40gFzf9s","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","\n","tf.enable_eager_execution()\n","\n","import numpy as np\n","import os\n","import re\n","import random\n","import unidecode\n","import time"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"pD_55cOxLkAb","colab":{}},"cell_type":"code","source":["path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"-E5JvY3wzf94","colab":{}},"cell_type":"code","source":["text = unidecode.unidecode(open(path_to_file).read())\n","print (len(text))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"IalZLbvOzf-F","colab":{}},"cell_type":"code","source":["unique = sorted(set(text))\n","\n","char2idx = {u:i for i, u in enumerate(unique)}\n","idx2char = {i:u for i, u in enumerate(unique)}"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"1v_qUYfAzf-I","colab":{}},"cell_type":"code","source":["max_length = 100\n","vocab_size = len(unique)\n","embedding_dim = 256\n","units = 1024\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 10000"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"0UHJDA39zf-O","colab":{}},"cell_type":"code","source":["input_text = []\n","target_text = []\n","\n","for f in range(0, len(text)-max_length, max_length):\n","    inps = text[f:f+max_length]\n","    targ = text[f+1:f+1+max_length]\n","\n","    input_text.append([char2idx[i] for i in inps])\n","    target_text.append([char2idx[t] for t in targ])\n","    \n","print (np.array(input_text).shape)\n","print (np.array(target_text).shape)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"p2pGotuNzf-S","colab":{}},"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices((input_text, target_text)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"P3KTiiInzf-a","colab":{}},"cell_type":"code","source":["class Model(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, units, batch_size):\n","    super(Model, self).__init__()\n","    self.units = units\n","    self.batch_sz = batch_size\n","\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","\n","    if tf.test.is_gpu_available():\n","      self.gru = tf.keras.layers.CuDNNGRU(self.units, \n","                                          return_sequences=True, \n","                                          return_state=True, \n","                                          recurrent_initializer='glorot_uniform')\n","    else:\n","      self.gru = tf.keras.layers.GRU(self.units, \n","                                     return_sequences=True, \n","                                     return_state=True, \n","                                     recurrent_activation='sigmoid', \n","                                     recurrent_initializer='glorot_uniform')\n","\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","        \n","  def call(self, x, hidden):\n","    x = self.embedding(x)\n","\n","    # output shape == (batch_size, max_length, hidden_size) \n","    # states shape == (batch_size, hidden_size)\n","\n","    output, states = self.gru(x, initial_state=hidden)\n","\n","\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","\n","    x = self.fc(output)\n","\n","    return x, states"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"7t2XrzEOzf-e","colab":{}},"cell_type":"code","source":["model = Model(vocab_size, embedding_dim, units, BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"dkjWIATszf-h","colab":{}},"cell_type":"code","source":["optimizer = tf.train.AdamOptimizer()\n","\n","def loss_function(real, preds):\n","    return tf.losses.sparse_softmax_cross_entropy(labels=real, logits=preds)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"oAGisDdfP9rL","colab":{}},"cell_type":"code","source":["checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 model=model)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"d4tSNwymzf-q","colab":{}},"cell_type":"code","source":["EPOCHS = 20\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","    \n","    hidden = model.reset_states()\n","    \n","    for (batch, (inp, target)) in enumerate(dataset):\n","          with tf.GradientTape() as tape:\n","              predictions, hidden = model(inp, hidden)\n","              \n","              target = tf.reshape(target, (-1,))\n","              loss = loss_function(target, predictions)\n","              \n","          grads = tape.gradient(loss, model.variables)\n","          optimizer.apply_gradients(zip(grads, model.variables))\n","\n","          if batch % 100 == 0:\n","              print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch+1,\n","                                                            batch,\n","                                                            loss))\n","    if (epoch + 1) % 5 == 0:\n","      checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","    print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"tyvpYomYQQkF","colab":{}},"cell_type":"code","source":["checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"WvuwZBX5Ogfd","colab":{}},"cell_type":"code","source":["num_generate = 1000\n","\n","start_string = 'Q'\n","input_eval = [char2idx[s] for s in start_string]\n","input_eval = tf.expand_dims(input_eval, 0)\n","\n","text_generated = ''\n","\n","hidden = [tf.zeros((1, units))]\n","for i in range(num_generate):\n","    predictions, hidden = model(input_eval, hidden)\n","\n","    predicted_id = tf.argmax(predictions[-1]).numpy()\n","    \n","    input_eval = tf.expand_dims([predicted_id], 0)\n","    \n","    text_generated += idx2char[predicted_id]\n","\n","print (start_string + text_generated)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"gtEd86sX5cB2","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}